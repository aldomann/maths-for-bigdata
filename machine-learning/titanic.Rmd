---
title: 'Delivery 3: Machine Learning'
author: "Alfredo Hernández"
date: "15 June 2018"
output:
  html_document:
    theme: cosmo
    highlight: tango
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
subtitle: Mathematics for Big Data
---

# Introduction

The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.

One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.

## Objective

The objective is to build a model with Machine Learning that can predict the survival chance of a given individual performing a binary classification.

## Data

The data can be downloaded from the [Titanic Competition](https://www.kaggle.com/c/titanic/data) on Kaggle.

It consists on a training set that contains the outcome (also known as the “ground truth”) for each passenger, and a test set to see how well the model performs on unseen data. For each passenger in the test set, we will use the trained model to predict whether or not they survived the sinking of the Titanic.

The features of the datasets are the following:

| Feature    | Description                                | Key                                                  |
|------------|--------------------------------------------|------------------------------------------------------|
| `survival` | Survival                                   | `0` = No, `1` = Yes                                  |
| `pclass`   | Ticket class                               | `1` = 1st, `2` = 2nd, `3` = 3rd                      |
| `sex`      | Sex                                        |                                                      |
| `age`      | Age in years                               |                                                      |
| `sibsp`    | # of siblings / spouses aboard the Titanic |                                                      |
| `parch`    | # of parents / children aboard the Titanic |                                                      |
| `ticket`   | Ticket number                              |                                                      |
| `fare`     | Passenger fare                             |                                                      |
| `cabin`    | Cabin number                               |                                                      |
| `embarked` | Port of Embarkation                        | `C` = Cherbourg, `Q` = Queenstown, `S` = Southampton |

## Software

We are going to use the `tidyverse` meta-package mainly for `dplyr` (data manipulation) and `magrittr` (to use pipes). For building the model, we are going to use the `randomForest` package. For ethnicity prediction we are going to need the package `wru`, as it is the only one that can do it without need of a US Census API Key.
```{r message=FALSE}
library(tidyverse)
library(randomForest)
library(wru)
```

Additionally, we will use some components of the following packages calling directly the namespace:

- `data.table` for fast processing of files.
- `caret` to calculate the confusion matrix in the cross validation process.

# 1. Data wrangling
In this process we will read the data and do a basic cleaning of the data.

## Reading the data
First of all, we need to read the data sets from the files:
```{r}
titanic.train <- data.table::fread("data/titanic_train.csv")
titanic.test <- data.table::fread("data/titanic_test.csv")
```

Since we are going to clean some features and perform feature engineering, we will bind the training and test data. We use the `bind_rows()` function from the `dplyr` package, as it matches columns by name, and any missing columns will be filled with `NA` (this is the case for `survived` in the test data set):
```{r}
titanic.full <- bind_rows(titanic.train, titanic.test)
names(titanic.full) <- tolower(names(titanic.full))
```

We will split again the data sets before we start building the predictive model.

Before doing anything with the data, let us have a look at it and its structure:
```{r}
glimpse(titanic.full)
```


## Checking missing values (`NA`s)

First of all, we check how many the full data set has:
```{r}
titanic.full %>%
  select( - survived) %>% 
  summarise_all(funs(sum(is.na(.))))
```

## Dealing with empty fields

But that's only half of the picture, as there are some features that have no content (they are empty), and need to be changed into `NA`s before dealing with them properly:
```{r}
titanic.full <- titanic.full %>%
  mutate_all(funs(replace(., . == "", NA)))
```

Now we can see that we are taking into consideration all actual `NA`s:
```{r}
titanic.full %>%
  select( - survived) %>% 
  summarise_all(funs(sum(is.na(.))))
```
We see three problematic features:
- `age` 
- `fare`
- `cabin`
- `embarked`

Notice that we have `r nrow(titanic.full)` observations. Dealing with `fare` and `embarked` should be relatively easy, so we will start with these. For `age` we need additional features that we will extract from the data, so we will deal with it later. In contrast, for `cabin` one could argue there is not enough data to perform a proper inference of the missing values; this will require some extra thought.

Sections 2-4 will deal with filling the `NA` and feature engineering that will either help that task, or be helpful for the predictive model (hopefully both).




# 2. Names and ethnicities
The `name`s by themselves are quite obviously not going to be a good predictor, so we need to extract useful information from it. 

## Surnames and titles
The two first obvious choices are:

a. Surnames
b. Titles (English honorifics)

To do this, we need to look at the structure of a name: `Surname, Title. Name Secondname`. Having this information, we can simply use regular expressions to extract these two new features:
```{r}
titanic.full <- titanic.full %>% 
  mutate(name = gsub("^((\\w+\\W+){4}\\w+).*$","\\1", name)) %>% 
  mutate(title = gsub("(.*, )|(\\..*)", "", name)) %>% 
  mutate(surname = gsub("(*,)|(\\,.*)", "", name))
```

Let us have a glance of the different `r length(unique(titanic.full$title))` titles:
```{r}
table(titanic.full$title)
```

We can notice the following things: 

- A few titles are military people, probably the crew of the ship; these will be put together into `Navy`.
- There a few rich/nobiliary people; these will generalised into `Sir` and `Lady` only.
- Some of the honorifics are French or Dutch; we will refactor this into the English standard.

```{r}
titanic.full$title <- titanic.full$title %>%
  plyr::revalue(c("Ms" = "Mrs",
                  "Mme" = "Mrs",
                  "Mlle" = "Miss"))
```

```{r}
titanic.full <- titanic.full %>% 
  mutate(
    title = ifelse(title %in% c("Dona", "Lady", "the Countess", "Jonkheer"), "Lady", title),
    title = ifelse(title %in% c("Don", "Sir"), "Sir", title),
    title = ifelse(title %in% c("Capt", "Major", "Col"), "Navy", title)
    )
```

Now we have a much more meaningful categorisation (only `r length(unique(titanic.full$title))` categories) of the `title`s:
```{r}
table(titanic.full$title)
```

## Ethnicities

Something that might be quite useful, not only as a feature by itself, but as an auxiliary variable to fill missing `age`s, is the ethnicity of the passengers.

First thing we do is to predict the ethnicity using US Census data (sadly, it is not possible to use data from 1912, but it will be hopefully be a good first approach to the problem):

```{r}
titanic.full <- predict_race(titanic.full, surname.only = T)
```

This will give probabilities of being white, black, hispanic, asian, or other, based on the surname:
```{r}
head(titanic.full %>% select(surname, starts_with("pred.")))
```


Now all we need to do is to select the 
```{r}
titanic.full <- titanic.full %>% 
  mutate(ethnicity = colnames(titanic.full %>% select(starts_with("pred.")))
         [max.col(titanic.full %>% select(starts_with("pred.")), ties.method="first")]
    ) %>% 
  select(- starts_with("pred.")) %>% 
  mutate(ethnicity = as.factor(ethnicity))
```

```{r}
titanic.full$ethnicity <- titanic.full$ethnicity %>%
  plyr::revalue(c("pred.whi" = "White",
                  "pred.bla" = "Black",
                  "pred.asi" = "Asian",
                  "pred.his" = "Hispanic",
                  "pred.oth" = "Other"))
```


From the data, the first thing we see is that most of the passengers were white:
```{r}
titanic.full %>% 
  select(ethnicity, sex) %>% 
  table()
```

It could be interesting to see an overview of the survival ratio as a function of `ethnicity` and `sex`: 
```{r}
ggplot(drop_na_(titanic.full, "survived")) +
  aes(x = as.factor(ethnicity), fill = as.factor(survived)) +
  geom_bar(aes(y = ..count../sum(..count..)), position = "fill") +
  facet_grid(sex ~ .) +
  labs(fill = "Survived", x = "Ethnicity", y = "Renomalised proportion")
```
This already lets us suspect that `sex` and `ethnicity` (especially the former) will have some influence on the survival chance.



<!-- Remember that we still have a missing `fare` value, so we need to categorise it this when we deal with it. -->


# 3. Economical status

First we will deal with the missing values that can be input by hand without an advanced inference model:

- `fare`
- `embarked`

## Missing fare value
Let us have a look at the passenger missing the `fare` feature:
```{r}
titanic.full[which(is.na(titanic.full$fare)),]
```
The relevant features to impute the `fare` would seem to be `pclass`, and `embarked`, so we will focus on those with `pclass` and `embarked` fixed:
```{r}
titanic.full %>%
  filter(pclass == 3, embarked == "S", is.na(fare) == F) %>% 
  ggplot() +
    geom_histogram(aes(x = fare), binwidth = 1, 
                   fill = "slateblue1", colour = "black") +
  labs(x = "Fare (USD)", y = "Count")
```

Looking at the histogram above, it would seem appropiate to impute the median `fare` for this `pclass` and `embarked` combination:
```{r}
titanic.full[which(is.na(titanic.full$fare)),]$fare <- 
  median(
  titanic.full %>%
    filter(pclass == 3, embarked == "S") %>% 
    select(fare) %>% 
    na.omit() %>% 
    unlist()
  )
```

## Fare categories

Let us see how many different unique values of `fare` are there and their distribution:
```{r}
length(unique(titanic.full$fare))

ggplot(titanic.full) +
  geom_histogram(aes(x = fare), binwidth = 5, 
                 fill = "slateblue1", colour = "black") +
  labs(x = "Fare (USD)", y = "Count")
```

That is definitely way too many, but we can prettify this data by categorising the fares into ranges, looking at the quantiles of the `fare` distribution.
```{r}
quantile(titanic.full$fare, na.rm = T)
```

A reasonable division for `fare` could be: 
- `<= 10`
- `10 <= 20`
- `20 <= 30`
- `< 30`

```{r}
titanic.full <- titanic.full %>% 
  mutate(fare.range = cut(fare, breaks = c(-Inf, 10, 20, 30, Inf), 
                          labels = c("<10", "10-20", "20-30", ">30")))
```

```{r}
table(is.na(titanic.full$fare.range))
```

## Missing embarkation place
Let us have a look at the passengers missing the `embarked` feature:
```{r}
titanic.full[which(is.na(titanic.full$embarked)),]
```

The relevant features to impute `embarked` would seem to be `pclass`, `fare`, and `fare.class` so we will focus on those:
```{r}
titanic.full %>% 
  filter(pclass == 1, 
         fare.range == ">30", 
         fare < 500,
         is.na(embarked) == F) %>% 
ggplot() +
  geom_boxplot(aes(x = as.factor(embarked), y = fare, fill = as.factor(embarked))) +
  geom_hline(yintercept = titanic.full[which(is.na(titanic.full$embarked)), "fare"][1], 
             linetype = "dashed", colour = "red") +
    labs(x = "Embarked", y = "Fare (USD)", fill = "Embarked")
```

The decision is not obvious, but `C` (Cherbourg) seems to be a better value, as the `fare` value approaches more the median of this `embarked` class.
```{r}
titanic.full <- titanic.full %>% 
  mutate(embarked = ifelse(passengerid %in% c(62, 830),
                           "C", embarked))
```

## Cabin and deck

Looking into the `cabin` values, we see that they follow some structure: they are composed by a letter (from `"A` to `G`, and a single value with `"T"`) and a room number. This letter most probably represents the deck and could give an important insight in the survival chance, as it should give a somehow acurate representation of where the passengers were located.

We discussed that trying to impute the cabin would be impractical and difficult, but extracting the `deck` from available data, and reconstructing it to the missing values seems quite reasonable. 

First of all, let us see how the `fare` relates to the `deck`:
```{r}
titanic.full %>% 
  mutate(deck = substr(cabin, 0, 1)) %>% 
  group_by(deck) %>% 
  filter(deck != "T", fare < 500) %>% 
  na.omit() %>% 
  ggplot() +
    aes(x = as.factor(deck), y = fare, fill = as.factor(deck)) +
    geom_boxplot() +
    labs(x = "Deck", y = "Fare (USD)", fill = "Deck")
```

It seems `fare` is a good feature to classify the `deck`. Since there is quite a lot of variability, it seems reasonable to build a discrete distribution model based on the mean (the median could work just as well), to fill the missing `deck` values:
```{r}
probs.fare <- titanic.full %>% 
  mutate(deck = substr(cabin, 0, 1)) %>% 
  group_by(deck) %>% 
  filter(deck != "T") %>% 
  summarise(mean.fare = mean(fare)) %>% 
  mutate(prob.fare = mean.fare/sum(mean.fare)) %>% 
  select(prob.fare) %>% 
  unlist()
```

```{r}
titanic.full <- titanic.full %>% 
  mutate(deck = substr(cabin, 0, 1)) %>% 
  mutate(deck = ifelse(is.na(deck), 
                       sample(c("A", "B", "C", "D", "E", "F", "G"), 
                              size = 1, replace = T, prob = probs.fare),
                       deck))
```

There surely is a better model to take into account the deviation associated to each `deck`, but this seems to be a reasonable first approach.

# 4. Ages and families

## Missing age values

Now that we have the `ethnicity`, we have more detailed information to predict the `age` of people based on `sex`, `title` (this can give insight into the age; for instance Master is used for young boys), and the former.

The idea is to replace the missing values by the mean of the combination group of `sex + ethnicity + title` to have more a more accurate representation:
```{r}
impute_group_median <- function(x) replace(x, is.na(x), median(x, na.rm = TRUE))

titanic.full <- titanic.full %>%
  plyr::ddply(~ sex + ethnicity + title, transform, age = impute_group_median(age))
```

Now we just check if there are any `NA`s that we could not impute with this method (for instance, a group without defined mean from the available data):
```{r}
table(is.na(titanic.full$age))
```

<!-- ## Age category -->
<!-- The seafaring command that women and children be the first to board the lifeboats when a ship abandoned gives us an idea on a useful predictive features. Since we already know the `sex`, we should build an `age.category`. -->

<!-- The decision seems quite straightforward: we should divide people into `"kid"`s and `"adult"`s. But another thing to consider is that senior people might move slower, or prioritise saving kids instead of themselves in an act of self-sacrifice. We have decided to divide ages into 4 categories: -->

<!-- - `"kid"`: up to 15 years old, to identify people who need the help of others to mobilise. -->
<!-- - `"young"`: from 15 to 35 years old. This might help identify mothers, as the average childbirth in the 1910s was 23 years old. -->
<!-- - `"adult"`: from 35 to 60 years old. -->
<!-- - `"senior"`: older than 60 years old; the eldery. -->

<!-- ```{r} -->
<!-- titanic.full <- titanic.full %>% -->
<!--   mutate(age.category = cut(age, breaks = c(-Inf, 15, 35, 60, Inf), -->
<!--                             labels = c("kid", "young", "adult", "senior"))) -->
<!--   # mutate(age.category = cut(age, breaks = c(-Inf, 15, Inf), -->
<!--                             # labels = c("kid", "adult"))) -->
<!-- ``` -->

## Family size
Rather than working with `sibsp` and `parch`, it seems that an aggregate feature of both would be more signigicant and useful: `family.size` that indicates the number of family members the passenger is travelling with:
```{r}
titanic.full <- titanic.full %>% 
  mutate(family.size =sibsp + parch + 1)
```




# 5. Exploratory analysis

Before building the predictive model, let us have a look at the new structure of the data set, and then explore how some variables can relate and explain the survival chance of passangers.

```{r}
glimpse(titanic.full)
```

```{r fig.height=10, fig.width=10}
gg.meta <- titanic.full %>% 
	filter(is.na(survived) == F,
				 fare < 500) %>% 
	ggplot() +
		aes(fill = as.factor(survived)) +
	labs(y = "Proportion", fill = "Survived")

gg.pclass <- gg.meta +
	geom_bar(aes(x = as.factor(pclass), y = ..count../sum(..count..)), position = "stack") +
	labs(x = "Ticket class")

gg.sex <- gg.meta +
	geom_bar(aes(x = as.factor(sex), y = ..count../sum(..count..)), position = "stack")+
	labs(x = "Sex")

gg.age <- gg.meta +
	geom_density(aes(x = age, y = ..count../sum(..count..)), alpha = 0.5)+
	labs(x = "Age")

gg.fare.range <- gg.meta +
	geom_bar(aes(x = as.factor(fare.range), y = ..count../sum(..count..)), position = "stack")+
	labs(x = "Fare range (USD)")

gg.deck <- gg.meta +
	geom_bar(aes(x = as.factor(deck), y = ..count../sum(..count..)), position = "stack")+
	labs(x = "Deck")

gg.ethn <- gg.meta +
	geom_bar(aes(x = as.factor(ethnicity), y = ..count../sum(..count..)), position = "stack")+
	labs(x = "Ethnicity")

gg.title <- gg.meta +
	geom_bar(aes(x = as.factor(title), y = ..count../sum(..count..)), position = "stack")+
	labs(x = "Title")

gg.fare <- gg.meta +
	geom_density(aes(x = fare, y = ..count../sum(..count..)), alpha = 0.5)+
	labs(x = "Fare (USD)")

gg.fam <- gg.meta +
	geom_bar(aes(x = as.factor(family.size), y = ..count../sum(..count..)), position = "stack")+
	labs(x = "Family size")

egg::ggarrange(plots = list(gg.sex, gg.age, 
														gg.pclass, gg.deck,
														gg.title, gg.fam,
														gg.fare, gg.ethn), nrow = 4)
```

Although this is just a very simple description of what's really going on, we can extract some possibly important factors on predicting the `survived` response:

- From the economical point of view, `pclass == 1` seems to have quite a big survival change when compared to the other two. 
- Males mostly die. This can be seen from `title == "Mr"` and `sex == "male"`.
- Children seem to survive quite a lot. This can be clearly seen in `survived` curve in the `age` distribution. 




# 6. Predictive model
For the predictive model we are going to use a Random Forest.

## Factoring the data
One important thing in R is that if we need to deal with predictive models (or models in general), having data as characters is not useful at all; we need to transform data into factors:
```{r}
titanic.full <- titanic.full %>% 
  mutate(survived = ifelse(survived == 1, "true", "false")) %>% 
  mutate_at(c("survived", "sex", "ticket", "cabin", "embarked", 
              "ethnicity", "title", "surname", "deck"),
            funs(factor(.)))
```

## Building a Random Forest

First of all, we will get rid of some features that should not help into predicting the survival chance (either because it is aggregated into another faeature, or because it is just noise):
```{r}
titanic.full.clean <- titanic.full %>% 
  arrange(passengerid) %>% 
  select(- c("name" ,"ticket", "cabin", "surname",
             "fare.range",
             "deck",
             "parch",
             "sibsp"
             ))

titanic.train <- titanic.full.clean[1:691,]
titanic.cv.test <- titanic.full.clean[692:891,]
titanic.test <- titanic.full.clean[892:1309,]
```

Now we just perform the Random Forest on the training set to model `survived` as the response:
```{r}
set.seed(42)
rf.titanic <- randomForest(survived~., data = titanic.train %>% select(- c("passengerid")), 
                           na.action = na.omit, importance = TRUE, ntree = 500)
```

Below we can see plot of the error rates of the model for OOB (out-of-bag), survived (True), and deceased (False) data:
```{r}
cbind(as.data.frame(rf.titanic$err.rate),
      trees = seq_along(rf.titanic$err.rate[,1])) %>%
  ggplot() +
    aes(x = trees) +
    geom_line(aes(y = OOB, colour = "OOB")) +
    geom_line(aes(y = true, colour = "True")) +
    geom_line(aes(y = false, colour = "False")) +
    scale_colour_manual(values = c("OOB" = "black",
                                   "True" = "green",
                                   "False" = "red"
    )) +
    labs(x = "Trees", y = "Error", colour = "Error")
```


We should take a look into the importance of each variable into predicting the `survived` value. This can help us "debug" our model and see which features are essentially useless when building the model:
```{r}
importance <- importance(rf.titanic)

data.frame(variables = row.names(importance),
           importance = round(importance[ ,'MeanDecreaseGini'], 2)) %>% 
  mutate(rank = paste0('#', dense_rank(desc(importance)))) %>% 
  ggplot() + 
    aes(x = reorder(variables, importance), y = importance, fill = importance) +
    geom_bar(stat = "identity", colour = "black") + 
    scale_fill_continuous(low = "slategray1", high = "slateblue1") +
    labs(x = "Variables", y = "Importance", fill = "Importance") +
    coord_flip()
```

## Cross validation
By default the random forest picks up (a) 2/3rd of the data for training and rest for testing for regression, and (b) almost 70% data for training and rest for testing during classification. By principle since it randomises the variable selection during each tree split it is not prone to overfit unlike other models.

Anyway, to cross validate the model, we use a small sample of the training data to perform a test of the predicted `survived` values, and compare it with the real `survived` values:
```{r}
titanic.cv.pred <- data.frame(passengerid = titanic.cv.test$passengerid, 
                            survived = predict(rf.titanic, titanic.cv.test, 
                                               OOB = TRUE, type = "response"))

titanic.cv.real <- data.frame(passengerid = titanic.cv.test$passengerid, 
                      survived = as.factor(titanic.cv.test$survived))
```
Now we can have a look at the confusion matrix to describe the performance of our model using the real data:
```{r}
caret::confusionMatrix(data = titanic.cv.pred$survived, 
                       reference = titanic.cv.real$survived)
```


## Prediction for the test data
Now that we have a rough idea of how good our model is, we can use the model to predict the real test data:
```{r}
titanic.test.pred <- data.frame(PassengerId = titanic.test$passengerid, 
                            Survived = predict(rf.titanic, titanic.test, 
                                               OOB = TRUE, type = "response")) 
titanic.test.pred$Survived <- titanic.test.pred$Survived %>% 
  plyr::revalue(c("true" = 1,
                  "false" = 0))
```

<!-- We can submit the data to the Kaggle competition to see the performance of our predictive model: -->
<!-- ```{r eval=FALSE} -->
<!-- write_csv(titanic.test.pred, "kaggle_titanic_predictions5.csv") -->
<!-- ``` -->

Since this is an academic problem, the solution is known and can be used to test the real accuracy of our predictive model. First we read the data:
```{r}
# Source: https://raw.githubusercontent.com/shezard/Titanic/master/data/solution.csv
titanic.solution <- data.table::fread("data/titanic_solution.csv")
```

And then we calculate the accuracy of the prediction:
```{r}
right_join(titanic.test.pred, titanic.solution, by = "PassengerId") %>% 
  mutate(good.pred = ifelse(Survived.x == Survived.y, T, F)) %>% 
  select(good.pred) %>% 
  table() %>% 
  prop.table()
```

We focused in two solutions:

- Including `deck` with an accuracy of 0.854067
- Not including `deck` with an accuracy of 0.8851675

Apparently, the method to generate missing `deck` values is not that accurate. This could mean that `NA` values in deck are actually significative, or that the `deck` by itself just adds noise, as we did not use the individual `fare` vales in the process of imputing the data (we only used `fare` to infer some kind of distribution of the `deck`).

# 7. Conclusions

Although random forest is a quite powerful technique, one must be careful with a few things:

- Over-engineering the data can lead to worse predictions, as it just adds noise to the model. As a general rule, when building a prediction model is the main goal of a study, often a minimal set of variables with good prediction performance is selected.
- Chosing the right models to fill missing data can be quite tricky and can lead to bias into the model.
